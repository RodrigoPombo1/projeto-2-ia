{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50517bdf",
   "metadata": {},
   "source": [
    "# Projeto 2: Aprendizagem Supervisionada - Previsão de aceitação de empréstimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b0ad5",
   "metadata": {},
   "source": [
    "## Instalação de bibliotecas\n",
    "\n",
    "Neste projeto usámos as seguintes bibliotecas:\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/) - \n",
    "- [numpy](https://numpy.org/) - \n",
    "- [sk-learn](https://scikit-learn.org) -  \n",
    "- [imbalanced-learn](https://imbalanced-learn.org) - \n",
    "- [xg-boost](https://xgboost.readthedocs.io/en/stable/python/python_intro.html) - \n",
    "\n",
    "Estas bibliotecas e as suas dependências podem ser instaladas ao correr o seguinte comando no root do projeto:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2644a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e6b8d",
   "metadata": {},
   "source": [
    "## Pré-processamento de dados\n",
    "\n",
    "### Parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714936bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_engineering(df):\n",
    "    median_emp_length = df['person_emp_length'].replace(0, np.nan).median()\n",
    "    df['person_emp_length'] = df['person_emp_length'].replace(0, median_emp_length)\n",
    "\n",
    "    df['financial_burden'] = df['loan_amnt'] * df['loan_int_rate'] / 100  \n",
    "\n",
    "    df['income_per_year_emp'] = df['person_income'] / (df['person_emp_length'] + 1e-5)\n",
    "    df['int_per_year_emp'] = df['loan_int_rate'] / (df['person_emp_length'] + 1e-5)\n",
    "\n",
    "    df['loan_to_credit_hist'] = df['loan_amnt'] / (df['cb_person_cred_hist_length'] + 1e-5)\n",
    "    df['loan_to_income_ratio'] = df['loan_amnt'] / (df['person_income'] + 1e-5)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_train(file_path: str, balance_classes: bool = False, use_feature_eng: bool = False):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "    if use_feature_eng:\n",
    "        df = feature_engineering(df)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=[\n",
    "        'person_home_ownership',\n",
    "        'loan_intent',\n",
    "        'loan_grade',\n",
    "        'cb_person_default_on_file'\n",
    "    ], drop_first=True)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    X = df.drop(columns=['loan_status'])\n",
    "    y = df['loan_status']\n",
    "\n",
    "    # Divide treino/validação antes de qualquer escala ou balanceamento\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    class_weights_dict = None  # Default\n",
    "\n",
    "    if balance_classes:\n",
    "       \n",
    "       \n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train),\n",
    "            y=y_train\n",
    "        )\n",
    "        class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "    # Agora escala os dados (separadamente treino e validação!)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    if balance_classes:\n",
    "        return X_train_scaled, X_val_scaled, y_train, y_val, scaler, X.columns, class_weights_dict\n",
    "    else:\n",
    "        return X_train_scaled, X_val_scaled, y_train, y_val, scaler, X.columns\n",
    "\n",
    "\n",
    "def preprocess_test(file_path: str, scaler, columns, use_feature_eng: bool = False):\n",
    "    df = pd.read_csv(file_path)\n",
    "    ids = df['id']\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "    if use_feature_eng:\n",
    "        df = feature_engineering(df)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=[\n",
    "        'person_home_ownership',\n",
    "        'loan_intent',\n",
    "        'loan_grade',\n",
    "        'cb_person_default_on_file'\n",
    "    ], drop_first=True)\n",
    "\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    df = df[columns]  # Reordenar colunas\n",
    "\n",
    "    X_scaled = scaler.transform(df)\n",
    "\n",
    "    return X_scaled, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9750340",
   "metadata": {},
   "source": [
    "#### preprocess_train\n",
    "\n",
    "- Inicialmente **removemos** variáveis não importantes como **Id**.\n",
    "\n",
    "    ```python\n",
    "    df = df.drop(columns=['id'])\n",
    "    ```\n",
    "\n",
    "- **Transformação** de variáveis **categóricas** em variáveis **binárias** (dummies).\n",
    "\n",
    "    ```python\n",
    "    df = pd.get_dummies(df, columns=[\n",
    "        'person_home_ownership',\n",
    "        'loan_intent',\n",
    "        'loan_grade',\n",
    "        'cb_person_default_on_file'\n",
    "    ], drop_first=True)\n",
    "    ```\n",
    "- Como temos **drop_first=True** ou seja vamos ter **mais N(numero de atributos) - 1** de **colunas**. \n",
    "\n",
    "- Variaveis categoricas:\n",
    "    - person_home_ownership:\n",
    "        - Own\n",
    "        - Mortgage\n",
    "        - Rent\n",
    "    - loan_intent:\n",
    "        - Education\n",
    "        - Medical\n",
    "        - Personal\n",
    "        - Venture\n",
    "        - Debt Consolidation\n",
    "        - Home Improvement\n",
    "    - loan_grade:\n",
    "        - A\n",
    "        - B\n",
    "        - C\n",
    "    - cb_person_default_on_file:\n",
    "        - Y\n",
    "        - N\n",
    "\n",
    "Dentro do treino dividimos entre treino e teste, 80% para treino real (X_train, y_train) e 20% para validação (X_val, y_val). Desta forma podemos testar o modelo antes de usar no teste oficial.\n",
    "\n",
    "```python\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "## Métodos para equilibrar resultados:\n",
    "\n",
    "### balance_classes:\n",
    "\n",
    "- Este método ajusta automaticamente o peso de cada classe com base na sua frequência inversa no conjunto de treino.\n",
    "- Ou seja, dá mais peso às classes minoritárias e menos peso às maioritárias, sem alterar os dados em si.\n",
    "\n",
    "```python\n",
    "if balance_classes:\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "```\n",
    "\n",
    "### Feature engineering:\n",
    "- Criar novas variáveis que combinam informação relevante para ajudar o modelo a detetar padrões mais facilmente — especialmente padrões relacionados com capacidade financeira e risco.\n",
    "\n",
    "```python\n",
    "def feature_engineering(df):\n",
    "    median_emp_length = df['person_emp_length'].replace(0, np.nan).median()\n",
    "    df['person_emp_length'] = df['person_emp_length'].replace(0, median_emp_length)\n",
    "\n",
    "    df['financial_burden'] = df['loan_amnt'] * df['loan_int_rate'] / 100  \n",
    "\n",
    "    df['income_per_year_emp'] = df['person_income'] / (df['person_emp_length'] + 1e-5)\n",
    "    df['int_per_year_emp'] = df['loan_int_rate'] / (df['person_emp_length'] + 1e-5)\n",
    "\n",
    "    df['loan_to_credit_hist'] = df['loan_amnt'] / (df['cb_person_cred_hist_length'] + 1e-5)\n",
    "    df['loan_to_income_ratio'] = df['loan_amnt'] / (df['person_income'] + 1e-5)\n",
    "\n",
    "    return df\n",
    "```\n",
    "\n",
    "#### Variaveis usadas:\n",
    "\n",
    "- **Correção** de valores **0** na coluna **person_emp_length** (anos de experiência profissional):\n",
    "    - Os zeros são substituídos pela mediana da coluna para evitar valores inválidos que podem prejudicar os cálculos subsequentes, nomeadamente divisões por zero. Isto melhora a qualidade e a robustez dos novos atributos criado\n",
    "\n",
    "    ```python\n",
    "    median_emp_length = df['person_emp_length'].replace(0, np.nan).median()\n",
    "    df['person_emp_length'] = df['person_emp_length'].replace(0, median_emp_length)\n",
    "    ```\n",
    "\n",
    "- **financial_burden**:\n",
    "    - Calcula uma estimativa do custo total dos juros do empréstimo, dado pelo produto do montante do empréstimo (loan_amnt) pela taxa de juro (loan_int_rate). Esta variável ajuda a captar o peso financeiro do empréstimo para o   indivíduo, que pode estar correlacionado com a probabilidade de incumprimento.\n",
    "\n",
    "    ```python\n",
    "    df['financial_burden'] = df['loan_amnt'] * df['loan_int_rate'] / 100\n",
    "    ```\n",
    "\n",
    "- **income_per_year_emp**:\n",
    "    - Mede o rendimento médio anual do indivíduo, obtido ao dividir o rendimento anual (person_income) pelo tempo de experiência profissional (person_emp_length). Esta variável reflete a capacidade financeira ajustada pelo tempo no mercado de trabalho, podendo indicar estabilidade ou crescimento da carreira.\n",
    "\n",
    "    ```python\n",
    "    df['income_per_year_emp'] = df['person_income'] / (df['person_emp_length'] + 1e-5)\n",
    "    ```\n",
    "\n",
    "- **int_per_year_emp**:\n",
    "    - Calcula a taxa de juro anual ajustada pelo tempo de experiência, dividindo a taxa de juro do empréstimo pela experiência profissional. Esta métrica pode evidenciar se o custo do empréstimo é elevado relativamente à experiência financeira da pessoa, o que pode impactar no risco de incumprimento.\n",
    "    ```python\n",
    "    df['int_per_year_emp'] = df['loan_int_rate'] / (df['person_emp_length'] + 1e-5)\n",
    "    ```\n",
    "- **loan_to_credit_hist**:\n",
    "    - Mede a relação entre o montante do empréstimo e o tempo de histórico de crédito, calculada dividindo o montante do empréstimo (loan_amnt) pelo tempo de histórico de crédito (cb_person_cred_hist_length). Esta variável coloco o montante do empréstimo em relação à experiência de crédito da pessoa, ajudando a identificar potenciais riscos.\n",
    "\n",
    "    ```python\n",
    "    df['loan_to_credit_hist'] = df['loan_amnt'] / (df['cb_person_cred_hist_length'] + 1e-5)\n",
    "    ```\n",
    "\n",
    "- **loan_to_income_ratio**:\n",
    "    - Calcula a relação entre o montante do empréstimo e quanto dinheiro a pessoa ganha anualmente, dividindo o montante do empréstimo (loan_amnt) pela receita anual (person_income). Esta métrica ajuda a avaliar a capacidade de pagamento do indivíduo, conseguimos então avaliar melhor se o empréstimo é excessivo em relação à capacidade de pagamento do indivíduo.\n",
    "\n",
    "    ```python\n",
    "    df['loan_to_income_ratio'] = df['loan_amnt'] / (df['person_income'] + 1e-5)\n",
    "    ```\n",
    "## Machine learning models\n",
    "\n",
    "O treino dos modelos é realizado através da função train_model(), com os parâmetros:\n",
    "  - trainFile_path: str - path para o ficheiro csv de treino\n",
    "  - classWeightbool: bool - true -> ativado, false -> desativado, o ajuste automático do peso das classes (dá mais peso às classes minoritárias e menos peso às maioritárias, sem alterar os dados em si)\n",
    "  - use_feature_eng: bool - true-> ativada, false ->desativada, a feature engineering (usa as novas variáveis criadas para ajudar o modelo a detetar padrões mais facilmente)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9972044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainFile_path: str, model, classWeightbool: bool = False, use_feature_eng: bool = False):\n",
    "    if classWeightbool:\n",
    "        # preprocess_train retorna class_weights quando balance_classes=True\n",
    "        X_train, X_val, y_train, y_val, scaler, columns, class_weights = preprocess_train(\n",
    "            trainFile_path, balance_classes=True, use_feature_eng=use_feature_eng\n",
    "        )\n",
    "        # Ajusta parâmetros do modelo para classes desbalanceadas\n",
    "        if isinstance(model, XGBClassifier):\n",
    "            counter = Counter(y_train)\n",
    "            weight = counter[0] / counter[1]\n",
    "            model.set_params(scale_pos_weight=weight)\n",
    "        elif hasattr(model, 'class_weight') and model.class_weight is None:\n",
    "            model.class_weight = class_weights\n",
    "    else:\n",
    "        # preprocess_train não retorna class_weights quando balance_classes=False\n",
    "        X_train, X_val, y_train, y_val, scaler, columns = preprocess_train(\n",
    "            trainFile_path, balance_classes=False, use_feature_eng=use_feature_eng\n",
    "        )\n",
    "        class_weights = None  # para consistência\n",
    "    \n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "\n",
    "    start_pred = time.time()\n",
    "    y_pred = model.predict(X_val)\n",
    "    end_pred = time.time()\n",
    "\n",
    "    print(\"Exatidão (validação):\", accuracy_score(y_val, y_pred))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_val, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(\"Matriz de confusão:\")\n",
    "    print(cm)\n",
    "\n",
    "    print(f\"Tempo de treino: {end_train - start_train:.4f} segundos\")\n",
    "    print(f\"Tempo de predição (validação): {end_pred - start_pred:.4f} segundos\")\n",
    "\n",
    "    return model, scaler, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8eca6",
   "metadata": {},
   "source": [
    "O teste dos modelos é realizado através da função test_model() com os parâmetros:\n",
    "- testFile_path: str - path para o ficheiro csv de teste\n",
    "- model: str - modelo a usar (logistic_regression, random_forest, xgboost)\n",
    "- scaler: StandardScaler - tipo de scaler a usar\n",
    "- columns: list[str] - lista de colunas a usar\n",
    "- use_feature_eng: bool - true-> ativada, false ->desativada, a feature engineering (usa as novas variáveis criadas para ajudar o modelo a detetar padrões mais facilmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ffa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(testFile_path: str, model, scaler, columns, use_feature_eng: bool = False):\n",
    "    start_test = time.time()\n",
    "    X_test, ids = preprocess_test(testFile_path, scaler, columns, use_feature_eng=use_feature_eng)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        result = y_proba\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        result = y_pred\n",
    "    end_test = time.time()\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'loan_status': result\n",
    "    })\n",
    "\n",
    "    result_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Submission saved on 'submission.csv'\")\n",
    "    print(f\"Tempo para processar teste: {end_test - start_test:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f63b83",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Nota:** Nas seguintes secções o calculo do tempo (tempo = tempo_treino + tempo_teste)\n",
    "\n",
    "### Logistic Regression:\n",
    "\n",
    "##### Parâmetros do modelo:\n",
    "\n",
    "- LogisticRegression(max_iter=1000, random_state=42, classWeightbool, use_feature_eng)\n",
    "  - max_iter = 1000\n",
    "  - random_state = 42\n",
    "  - classWeightbool\n",
    "  - use_feature_eng\n",
    "\n",
    "##### Parâmetros da função wrapper:\n",
    "\n",
    "Com a função logisticRegression() que tem os parâmetros:\n",
    "- trainFile_path: str - path para o ficheiro csv de treino\n",
    "- testFile_path: str - path para o ficheiro csv de teste\n",
    "- classWeightbool: bool - true -> ativado, false -> desativado, o ajuste automático do peso das classes (dá mais peso às classes minoritárias e menos peso às maioritárias, sem alterar os dados em si)\n",
    "- use_feature_eng: bool - true-> ativada, false ->desativada, a feature engineering (usa as novas variáveis criadas para ajudar o modelo a detetar padrões mais facilmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce35330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(trainFile_path: str, testFile_path: str, classWeightbool: bool, use_feature_eng: bool):\n",
    "    start_time = time.time()\n",
    "\n",
    "    modelUsed = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model, scaler, columns = train_model(trainFile_path, modelUsed, classWeightbool, use_feature_eng)\n",
    "    test_model(testFile_path, model, scaler, columns,use_feature_eng)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"[LogisticRegression] Tempo de execução: {end_time - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebbce0",
   "metadata": {},
   "source": [
    "#### Treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8084aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.911842441810896\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     10087\n",
      "           1       0.77      0.53      0.63      1642\n",
      "\n",
      "    accuracy                           0.91     11729\n",
      "   macro avg       0.85      0.75      0.79     11729\n",
      "weighted avg       0.90      0.91      0.90     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9832  255]\n",
      " [ 779  863]]\n",
      "Tempo de treino: 1.5373 segundos\n",
      "Tempo de predição (validação): 0.0010 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.1152 segundos\n",
      "[LogisticRegression] Tempo de execução: 2.10 segundos\n"
     ]
    }
   ],
   "source": [
    "logisticRegression('data/train.csv', 'data/test.csv', classWeightbool=False, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad8e1d",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.911842441810896\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification | Precision | Recall | F1-Score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 0.93      | 0.97   | 0.95     | 10087   |\n",
    "| 1     | 0.77      | 0.53   | 0.63     | 1642    |\n",
    "| **Accuracy**     |        |          | 0.91     | 11729   |\n",
    "| **Macro Avg**    | 0.85   | 0.75     | 0.79     | 11729   |\n",
    "| **Weighted Avg** | 0.90   | 0.91     | 0.90     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9832  255]\n",
    " [ 779  863]]\n",
    "\n",
    "**Tempo de treino:** 0.0700 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.0000 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.0810 segundos\n",
    "\n",
    "**Tempo de execução:** 0.37 segundos\n",
    "\n",
    "##### Conclusão:\n",
    "\n",
    "- Bons resultados para um modelo tão simples porem existe um possivel fator problematico que é a taxa de recall para load approval 1 que é de 0,53 significa que o modelo só identifica 53% dos clientes problemáticos.\n",
    "- O que pode ser causado pelo um maior numero de 0 do que 1\n",
    "- Solução: \n",
    "    - usar tecnicas para equilibrar os dados\n",
    "\n",
    "#### Treino com balance_classes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82f2cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.8397987893256033\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90     10087\n",
      "           1       0.46      0.83      0.59      1642\n",
      "\n",
      "    accuracy                           0.84     11729\n",
      "   macro avg       0.71      0.84      0.75     11729\n",
      "weighted avg       0.90      0.84      0.86     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[8484 1603]\n",
      " [ 276 1366]]\n",
      "Tempo de treino: 1.3729 segundos\n",
      "Tempo de predição (validação): 0.0011 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.1005 segundos\n",
      "[LogisticRegression] Tempo de execução: 1.93 segundos\n"
     ]
    }
   ],
   "source": [
    "logisticRegression('data/train.csv', 'data/test.csv', classWeightbool=True, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca134775",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.8397987893256033\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification | Precision | Recall | F1-Score | Support |\n",
    "|----------------|-----------|--------|----------|---------|\n",
    "| 0              | 0.97      | 0.84   | 0.90     | 10087   |\n",
    "| 1              | 0.46      | 0.83   | 0.59     | 1642    |\n",
    "| **Accuracy**   |           |        | 0.84     | 11729   |\n",
    "| **Macro Avg**  | 0.71      | 0.84   | 0.75     | 11729   |\n",
    "| **Weighted Avg** | 0.90    | 0.84   | 0.86     | 11729   |\n",
    "\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[8484 1603]\n",
    " [ 276 1366]]\n",
    "\n",
    "**Tempo de treino:** 0.0780 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.0000 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.0900 segundos\n",
    "\n",
    "**Tempo de execução:** 0.39 segundos\n",
    "\n",
    "##### Conclusão:\n",
    "\n",
    "- Melhorou o recall porem pirou outras metricas talvez mais importantes como a precisao e o f1-score, levando um aumento do numero de falsos negativos\n",
    "- Isto aconteceu pois o modelo dá mais importância à classe minoritária (no teu caso, o loan_status = 1). \n",
    "\n",
    "#### Uso de Feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50fd0bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9149970159433882\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     10087\n",
      "           1       0.78      0.55      0.64      1642\n",
      "\n",
      "    accuracy                           0.91     11729\n",
      "   macro avg       0.85      0.76      0.80     11729\n",
      "weighted avg       0.91      0.91      0.91     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9828  259]\n",
      " [ 738  904]]\n",
      "Tempo de treino: 2.9902 segundos\n",
      "Tempo de predição (validação): 0.0008 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.1352 segundos\n",
      "[LogisticRegression] Tempo de execução: 3.64 segundos\n"
     ]
    }
   ],
   "source": [
    "logisticRegression('data/train.csv', 'data/test.csv', classWeightbool=False, use_feature_eng=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcdba0",
   "metadata": {},
   "source": [
    "**Exatidão (validação):** 0.9149970159433882\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification | Precision | Recall | F1-Score | Support |\n",
    "|----------------|-----------|--------|----------|---------|\n",
    "| 0              | 0.93      | 0.97   | 0.95     | 10087   |\n",
    "| 1              | 0.78      | 0.55   | 0.64     | 1642    |\n",
    "| **Accuracy**   |           |        | 0.91     | 11729   |\n",
    "| **Macro Avg**  | 0.85      | 0.76   | 0.80     | 11729   |\n",
    "| **Weighted Avg** | 0.91    | 0.91   | 0.91     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9828  259]\n",
    " [ 738  904]]\n",
    "\n",
    "**Tempo de treino:** 0.1280 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.0010 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.0950 segundos\n",
    "\n",
    "**Tempo de execução:** 0.48 segundos\n",
    "\n",
    "##### Análise dos resultados:\n",
    "\n",
    "- O recall subiu de 0.53 → 0.55\n",
    "\n",
    "- O f1-score subiu de 0.63 → 0.64\n",
    "\n",
    "- Isto significa que o modelo passou a identificar um pouco melhor quem não paga o empréstimo, sem perder qualidade nos outros caso\n",
    "\n",
    "##### Interpretação\n",
    "\n",
    "- Class weights também estão a ajudar o modelo a tratar a classe 1 com mais importância.\n",
    "\n",
    "- O teste (sem nada) obtém maior exatidão  mas ignora a classe 1, o que é problematico em problemas de fraude ou risco.\n",
    "\n",
    "### Random Forest Classifier:\n",
    "\n",
    "##### Parâmetros do modelo:\n",
    "- randomForestClassifier(n_estimators=100, random_state=42, classWeightbool, use_feature_eng)\n",
    "  - n_estimators = 100\n",
    "  - random_state = 42\n",
    "  - classWeightbool\n",
    "  - use_feature_eng\n",
    "\n",
    "##### Parâmetros da função wrapper:\n",
    "Com a função randomForest() que tem os parâmetros:\n",
    "- trainFile_path: str - path para o ficheiro csv de treino\n",
    "- testFile_path: str - path para o ficheiro csv de teste\n",
    "- classWeightbool: bool - true -> ativado, false -> desativado, o ajuste automático do peso das classes (dá mais peso às classes minoritárias e menos peso às maioritárias, sem alterar os dados em si)\n",
    "- use_feature_eng: bool - true-> ativada, false ->desativada, a feature engineering (usa as novas variáveis criadas para ajudar o modelo a detetar padrões mais facilmente)\n",
    "\n",
    "#### Treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12603d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(trainFile_path: str, testFile_path: str, classWeightbool: bool,use_feature_eng: bool):\n",
    "        start_time = time.time()\n",
    "\n",
    "        modelUsed = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            class_weight='balanced' if classWeightbool else None\n",
    "        )\n",
    "        model, scaler, columns = train_model(trainFile_path, modelUsed, classWeightbool,use_feature_eng)\n",
    "        test_model(testFile_path, model, scaler, columns,use_feature_eng)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"[RandomForest] Tempo de execução: {end_time - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2effff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9517435416489044\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     10087\n",
      "           1       0.92      0.72      0.81      1642\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.86      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9977  110]\n",
      " [ 456 1186]]\n",
      "Tempo de treino: 5.6249 segundos\n",
      "Tempo de predição (validação): 0.2146 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.7609 segundos\n",
      "[RandomForest] Tempo de execução: 6.94 segundos\n"
     ]
    }
   ],
   "source": [
    "randomForest('data/train.csv', 'data/test.csv', classWeightbool=False, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac2882",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.9517435416489044\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification   | Precision | Recall | F1-Score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| 0                | 0.96      | 0.99   | 0.97     | 10087   |\n",
    "| 1                | 0.92      | 0.72   | 0.81     | 1642    |\n",
    "| **Accuracy**     |           |        | 0.95     | 11729   |\n",
    "| **Macro Avg**    | 0.94      | 0.86   | 0.89     | 11729   |\n",
    "| **Weighted Avg** | 0.95      | 0.95   | 0.95     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9977  110]\n",
    " [ 456 1186]]\n",
    "\n",
    "**Tempo de treino:** 4.2620 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.1930 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.6830 segundos\n",
    "\n",
    "**Tempo de execução:** 5.36 segundos\n",
    "\n",
    "##### Conclusão:\n",
    "\n",
    "- Foi especialmente superior na classe minoritária, onde o modelo de regressão logística teve um desempenho mais fraco (recall 0.53 vs 0.72).\n",
    "\n",
    "- Não foi necessário Equilibrio explícito ( class_weight) para a Random Forest ter um bom desempenho — isso é esperado, porque Random Forest lida melhor com desEquilibrio ao não ser um modelo linear e ao fazer bootstrapping com vários subconjuntos dos dados.\n",
    "\n",
    "#### Random Forest Classifier com class_weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81f4bac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9514877653678916\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     10087\n",
      "           1       0.92      0.71      0.80      1642\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.85      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9989   98]\n",
      " [ 471 1171]]\n",
      "Tempo de treino: 5.5456 segundos\n",
      "Tempo de predição (validação): 0.2064 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.7668 segundos\n",
      "[RandomForest] Tempo de execução: 6.78 segundos\n"
     ]
    }
   ],
   "source": [
    "randomForest('data/train.csv', 'data/test.csv', classWeightbool=True, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754de92",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.9514877653678916\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification   | Precision | Recall | F1-Score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| 0                | 0.95      | 0.99   | 0.97     | 10087   |\n",
    "| 1                | 0.92      | 0.71   | 0.80     | 1642    |\n",
    "| **Accuracy**     |           |        | 0.95     | 11729   |\n",
    "| **Macro Avg**    | 0.94      | 0.85   | 0.89     | 11729   |\n",
    "| **Weighted Avg** | 0.95      | 0.95   | 0.95     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9989   98]\n",
    " [ 471 1171]]\n",
    "\n",
    "**Tempo de treino:** 4.3159 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.1670 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.6889 segundos\n",
    "\n",
    "**Tempo de execução:** 5.38 segundos\n",
    "\n",
    "##### Conclusão:\n",
    "\n",
    "- Random Forest com class_weight não tem qualquer melhoria mas ja era esperado   porque Random Forest lida melhor com desEquilibrio ao não ser um modelo linear e ao fazer bootstrapping com vários subconjuntos dos dados.\n",
    "\n",
    "\n",
    "#### Random Forest Classifier com Feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64721cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9470543098303351\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     10087\n",
      "           1       0.89      0.71      0.79      1642\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.92      0.85      0.88     11729\n",
      "weighted avg       0.95      0.95      0.94     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9950  137]\n",
      " [ 484 1158]]\n",
      "Tempo de treino: 11.3646 segundos\n",
      "Tempo de predição (validação): 0.2149 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.9898 segundos\n",
      "[RandomForest] Tempo de execução: 12.84 segundos\n"
     ]
    }
   ],
   "source": [
    "randomForest('data/train.csv', 'data/test.csv', classWeightbool=False, use_feature_eng=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827490e",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.9470543098303351\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification   | Precision | Recall | F1-Score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| 0                | 0.95      | 0.99   | 0.97     | 10087   |\n",
    "| 1                | 0.89      | 0.71   | 0.79     | 1642    |\n",
    "| **Accuracy**     |           |        | 0.95     | 11729   |\n",
    "| **Macro Avg**    | 0.92      | 0.85   | 0.88     | 11729   |\n",
    "| **Weighted Avg** | 0.95      | 0.95   | 0.94     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9950  137]\n",
    " [ 484 1158]]\n",
    "\n",
    "**Tempo de treino:** 8.4121 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.1850 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.7240 segundos\n",
    "\n",
    "**Tempo de execução:** 9.57 segundos\n",
    "\n",
    "##### Conclusão:\n",
    "\n",
    "- Estas features podem a acrescentar alguma redundancia desbalancear a árvore ao fazer splits em features artificiais menos relevantes\n",
    "\n",
    "### XGBoost:\n",
    "\n",
    "##### Parâmetros do modelo:\n",
    "- XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, subsmple=0.8, colsample_bytree=0.8, random_state=42, eval_metric='logloss')\n",
    "  - n_estimators = 100\n",
    "  - random_state = 42\n",
    "  - learning_rate = 0.1\n",
    "  - max_depth = 6\n",
    "  - subsmple = 0.8\n",
    "  - colsample_bytree = 0.8\n",
    "  - random_state = 42\n",
    "  - eval_metric = 'logloss'\n",
    "\n",
    "##### Parâmetros da função wrapper:\n",
    "Com a função xboost_model() que tem os parâmetros:\n",
    "- trainFile_path: str - path para o ficheiro csv de treino\n",
    "- testFile_path: str - path para o ficheiro csv de teste\n",
    "- classWeightbool: bool - true -> ativado, false -> desativado, o ajuste automático do peso das classes (dá mais peso às classes minoritárias e menos peso às maioritárias, sem alterar os dados em si)\n",
    "- use_feature_eng: bool - true-> ativada, false ->desativada, a feature engineering (usa as novas variáveis criadas para ajudar o modelo a detetar padrões mais facilmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f62f7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(trainFile_path: str, testFile_path: str, classWeightbool: bool, use_feature_eng: bool):\n",
    "    start_time = time.time()\n",
    "\n",
    "    modelUsed = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "    )\n",
    "\n",
    "    # Treina e testa o modelo\n",
    "    model, scaler, columns = train_model(trainFile_path, modelUsed, classWeightbool, use_feature_eng)\n",
    "    test_model(testFile_path, model, scaler, columns, use_feature_eng)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"[XGBoost] Tempo de execução: {end_time - start_time:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23af16d",
   "metadata": {},
   "source": [
    "#### Treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37eda114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9533634580953193\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     10087\n",
      "           1       0.91      0.74      0.82      1642\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.86      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9974  113]\n",
      " [ 434 1208]]\n",
      "Tempo de treino: 1.7767 segundos\n",
      "Tempo de predição (validação): 0.0144 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.1084 segundos\n",
      "[XGBoost] Tempo de execução: 2.17 segundos\n"
     ]
    }
   ],
   "source": [
    "xgboost_model('data/train.csv', 'data/test.csv', classWeightbool=False, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429885f4",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.9534487168556569\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification   | Precision | Recall | F1-Score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| 0                | 0.96      | 0.99   | 0.97     | 10087   |\n",
    "| 1                | 0.92      | 0.74   | 0.82     | 1642    |\n",
    "| **Accuracy**     |           |        | 0.95     | 11729   |\n",
    "| **Macro Avg**    | 0.94      | 0.86   | 0.89     | 11729   |\n",
    "| **Weighted Avg** | 0.95      | 0.95   | 0.95     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9975  112]\n",
    " [ 434 1208]]\n",
    "\n",
    "**Tempo de treino:** 0.4500 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.0080 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.1390 segundos\n",
    "\n",
    "**Tempo de execução:** 0.87 segundos\n",
    "\n",
    "#### Treino com balance_classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e603d24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9263364310682922\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     10087\n",
      "           1       0.70      0.83      0.76      1642\n",
      "\n",
      "    accuracy                           0.93     11729\n",
      "   macro avg       0.84      0.89      0.86     11729\n",
      "weighted avg       0.93      0.93      0.93     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9505  582]\n",
      " [ 282 1360]]\n",
      "Tempo de treino: 0.8269 segundos\n",
      "Tempo de predição (validação): 0.0123 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.1022 segundos\n",
      "[XGBoost] Tempo de execução: 1.25 segundos\n"
     ]
    }
   ],
   "source": [
    "xgboost_model('data/train.csv', 'data/test.csv', classWeightbool=True, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd541180",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.9252280671839032\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification   | Precision | Recall | F1-Score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| 0                | 0.97      | 0.94   | 0.96     | 10087   |\n",
    "| 1                | 0.70      | 0.83   | 0.76     | 1642    |\n",
    "| **Accuracy**     |           |        | 0.93     | 11729   |\n",
    "| **Macro Avg**    | 0.83      | 0.89   | 0.86     | 11729   |\n",
    "| **Weighted Avg** | 0.93      | 0.93   | 0.93     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9489  598]\n",
    " [ 279 1363]]\n",
    "\n",
    "**Tempo de treino:** 0.3060 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.0070 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.1350 segundos\n",
    "**Tempo de execução:** 0.73 segundos\n",
    "\n",
    "##### Conclusão:\n",
    "\n",
    "- Melhorou o recall porem pirou outras metricas talvez mais importantes como a precisao e o f1-score, levando um aumento do numero de falsos negativos\n",
    "- Isto aconteceu pois o modelo dá mais importância à classe minoritária (no teu caso, o loan_status = 1). \n",
    "\n",
    "#### Uso de Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07e552e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exatidão (validação): 0.9533634580953193\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     10087\n",
      "           1       0.91      0.74      0.82      1642\n",
      "\n",
      "    accuracy                           0.95     11729\n",
      "   macro avg       0.94      0.86      0.89     11729\n",
      "weighted avg       0.95      0.95      0.95     11729\n",
      "\n",
      "Matriz de confusão:\n",
      "[[9974  113]\n",
      " [ 434 1208]]\n",
      "Tempo de treino: 0.7922 segundos\n",
      "Tempo de predição (validação): 0.0077 segundos\n",
      "Submission saved on 'submission.csv'\n",
      "Tempo para processar teste: 0.0991 segundos\n",
      "[XGBoost] Tempo de execução: 1.15 segundos\n"
     ]
    }
   ],
   "source": [
    "xgboost_model('data/train.csv', 'data/test.csv', classWeightbool=False, use_feature_eng=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84c51c",
   "metadata": {},
   "source": [
    "##### Resultados:\n",
    "\n",
    "**Exatidão (validação):** 0.9499531076818143\n",
    "\n",
    "**Classification report:**\n",
    "\n",
    "| Classification   | Precision | Recall | F1-Score | Support |\n",
    "|------------------|-----------|--------|----------|---------|\n",
    "| 0                | 0.96      | 0.99   | 0.97     | 10087   |\n",
    "| 1                | 0.90      | 0.72   | 0.80     | 1642    |\n",
    "| **Accuracy**     |           |        | 0.95     | 11729   |\n",
    "| **Macro Avg**    | 0.93      | 0.86   | 0.89     | 11729   |\n",
    "| **Weighted Avg** | 0.95      | 0.95   | 0.95     | 11729   |\n",
    "\n",
    "**Matriz de confusão:**\n",
    "[[9953  134]\n",
    " [ 453 1189]]\n",
    "\n",
    "**Tempo de treino:** 0.3670 segundos\n",
    "\n",
    "**Tempo de predição (validação):** 0.0080 segundos\n",
    "\n",
    "**Tempo para processar teste:** 0.1570 segundos\n",
    "\n",
    "**Tempo de execução:** 0.83 segundos\n",
    "\n",
    "##### Interpretação\n",
    "\n",
    "- O modelo base é forte para a classe maioritária, mas perde alguns positivos.\n",
    "\n",
    "- Equilibrio melhora o recall da classe minoritária, mas prejudica precisão e f1-score, aumentando falsos positivos.\n",
    "\n",
    "- Feature engineering ajudou pouco, mantendo resultados similares.\n",
    "\n",
    "- Dependendo do objetivo, pode-se escolher entre maior precisão (modelo base) ou maior recall (Equilibrio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
